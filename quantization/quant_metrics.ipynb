{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import psutil\n",
    "import pynvml\n",
    "\n",
    "from thop import profile\n",
    "from thop import clever_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize with the MNIST mean and std\n",
    "])\n",
    "train_data = datasets.MNIST(root='/scratch/joluseti/local_datasets', train=True, download=False, transform=transform)\n",
    "test_data = datasets.MNIST(root='/scratch/joluseti/local_datasets', train=False, download=False, transform=transform)\n",
    "\n",
    "# Create the dictionary\n",
    "label_data_dict = {}\n",
    "for data, label in train_data:\n",
    "    if label not in label_data_dict:  # Add only one sample per label\n",
    "        label_data_dict[label] = data\n",
    "        # Break early if all labels are collected\n",
    "        if len(label_data_dict) == 10:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For test data\n",
    "test_data_dict = {}\n",
    "for data, label in test_data:\n",
    "    if label not in test_data_dict:\n",
    "        test_data_dict[label] = []  # Initialize a list for each label\n",
    "    test_data_dict[label].append(data)  # Append the data to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 7, Data shape: 1028\n",
      "Label: 2, Data shape: 1032\n",
      "Label: 1, Data shape: 1135\n",
      "Label: 0, Data shape: 980\n",
      "Label: 4, Data shape: 982\n",
      "Label: 9, Data shape: 1009\n",
      "Label: 5, Data shape: 892\n",
      "Label: 6, Data shape: 958\n",
      "Label: 3, Data shape: 1010\n",
      "Label: 8, Data shape: 974\n"
     ]
    }
   ],
   "source": [
    "for label, data in test_data_dict.items():\n",
    "    print(f\"Label: {label}, Data shape: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_data, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = label_data_dict[0].unsqueeze(0)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantLenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.quant = torch.ao.quantization.QuantStub()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 5, bias=False)\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2) \n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels = 16, kernel_size = 5, bias=False)\n",
    "        self.fc1 = nn.Linear(in_features = 16 * 4 * 4, out_features = 120, bias = False)\n",
    "        self.fc2 = nn.Linear(in_features = 120, out_features = 84, bias=False)\n",
    "        self.fc3 = nn.Linear(in_features = 84, out_features = 10, bias=False)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.dequant = torch.ao.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        y = x.reshape(-1, 16 * 4 * 4)\n",
    "        x = x.reshape(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.dequant(x)\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantLenet(\n",
       "  (quant): QuantStub()\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "  (fc1): Linear(in_features=256, out_features=120, bias=False)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=False)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=False)\n",
       "  (relu1): ReLU()\n",
       "  (relu2): ReLU()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = '/scratch/joluseti/618/model/float_model.pth'\n",
    "float_model = torch.load(model_path, weights_only=False).to('cpu')\n",
    "float_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=QuantLenet\n",
       "  (quant): RecursiveScriptModule(original_name=QuantStub)\n",
       "  (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "  (pool): RecursiveScriptModule(original_name=MaxPool2d)\n",
       "  (conv2): RecursiveScriptModule(original_name=Conv2d)\n",
       "  (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "  (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "  (fc3): RecursiveScriptModule(original_name=Linear)\n",
       "  (relu1): RecursiveScriptModule(original_name=ReLU)\n",
       "  (relu2): RecursiveScriptModule(original_name=ReLU)\n",
       "  (dequant): RecursiveScriptModule(original_name=DeQuantStub)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the float and quantized models\n",
    "model = torch.jit.load('/scratch/joluseti/618/test/float.pth')\n",
    "\n",
    "# Set both models to evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, _ = model(image)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of macs 281640.0, number of parameters 44190.0\n",
      "number of macs 281.640K, number of parameters 44.190K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "macs, params = profile(float_model, inputs=(image, ), verbose=False)\n",
    "read_macs, read_params = clever_format([macs, params], \"%.3f\")\n",
    "print(f\"number of macs {macs}, number of parameters {params}\")\n",
    "print(f\"number of macs {read_macs}, number of parameters {read_params}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44190"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "  \"\"\"\n",
    "  Counts the total number of trainable parameters in a PyTorch model.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch nn.Module object.\n",
    "\n",
    "  Returns:\n",
    "    int: The total number of trainable parameters.\n",
    "  \"\"\"\n",
    "  total_params = 0\n",
    "  for param in model.parameters():\n",
    "    if param.requires_grad:  # Only count trainable parameters\n",
    "      num_params = 1\n",
    "      for size in param.size():\n",
    "        num_params *= size\n",
    "      total_params += num_params\n",
    "  return total_params\n",
    "\n",
    "count_parameters(float_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memoryInfo.total: 80.00 GB;   memoryInfo.used: 1.06 GB;   memoryInfo.free: 78.94 GB;   gpuTemperature: 26 C;   gpuEnergyUsage: 1856224846297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_gpu_info():\n",
    "    UNIT = 1024 * 1024 * 1024\n",
    "    pynvml.nvmlInit()\n",
    "    gpuDeriveInfo = pynvml.nvmlSystemGetDriverVersion()\n",
    "\n",
    "    gpuDeviceCount = pynvml.nvmlDeviceGetCount()\n",
    "    #print(\"Number of GPUï¼š\", gpuDeviceCount )\n",
    "\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "    memoryInfo = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "    gpuTemperature = pynvml.nvmlDeviceGetTemperature(handle, 0)\n",
    "    gpuEnergyUsage = pynvml.nvmlDeviceGetTotalEnergyConsumption(handle)\n",
    "    gpuPowerState = pynvml.nvmlDeviceGetPowerState(handle)\n",
    "    #gpuUtilRate = pynvml.nvmlDeviceGetUtilizationRates(handle).gpu\n",
    "    #gpuMemoryRate = pynvml.nvmlDeviceGetUtilizationRates(handle).memory\n",
    "    print(f\"memoryInfo.total: {memoryInfo.total/UNIT:.2f} GB;   memoryInfo.used: {memoryInfo.used/UNIT:.2f} GB;   memoryInfo.free: {memoryInfo.free/UNIT:.2f} GB;   gpuTemperature: {gpuTemperature} C;   gpuEnergyUsage: {gpuEnergyUsage}\\n\")\n",
    "\n",
    "\n",
    "def get_current_energy():\n",
    "    pynvml.nvmlInit()\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "    gpuEnergyUsage = pynvml.nvmlDeviceGetTotalEnergyConsumption(handle)\n",
    "    return gpuEnergyUsage\n",
    "\n",
    "get_gpu_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "GPU: NVIDIA A100-SXM4-80GB MIG 1g.10gb\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "print(\"GPU:\",torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat = 200\n",
    "\n",
    "def print_res(macs, total_time, total_energy):\n",
    "    print(f\"Average Energy (per inference) => {total_energy:.4f}\")\n",
    "    print(f\"Average Time (per inference) => {total_time*1000:.4f}ms\")\n",
    "    print(f\"GOPS/KJ => {((repeat*macs/(1024**3)) / (total_energy*(10**-3))):.4f}\")\n",
    "    print(f\"GOPs => {((repeat*macs/(1024**3))/ total_time):.4f}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_model(model, image, repeat):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model = model.to(device)\n",
    "    input_tensor = image.to(device)\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    for _ in range(5):\n",
    "        with torch.no_grad():\n",
    "            model(input_tensor)\n",
    "\n",
    "    total_time = 0\n",
    "    total_energy = 0\n",
    "\n",
    "\n",
    "    for _ in range(repeat):\n",
    "      energy_start = get_current_energy()\n",
    "\n",
    "      torch.cuda.synchronize()\n",
    "      time_start = time.time()\n",
    "\n",
    "      with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "\n",
    "      torch.cuda.synchronize()\n",
    "      time_end = time.time()\n",
    "\n",
    "      energy_end = get_current_energy()\n",
    "\n",
    "      total_time += (time_end - time_start)\n",
    "      total_energy += (energy_end - energy_start)\n",
    "\n",
    "    return total_time / repeat, total_energy / repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU info before benchmarking model:\n",
      "memoryInfo.total: 80.00 GB;   memoryInfo.used: 1.06 GB;   memoryInfo.free: 78.94 GB;   gpuTemperature: 25 C;   gpuEnergyUsage: 1856282772501\n",
      "\n",
      "Benchmarking model ...\n",
      "\n",
      "Average Energy (per inference) => 315.6650\n",
      "Average Time (per inference) => 0.2017ms\n",
      "GOPS/KJ => 0.1662\n",
      "GOPs => 260.1334\n",
      "\n",
      "GPU info after benchmarking model:\n",
      "memoryInfo.total: 80.00 GB;   memoryInfo.used: 1.06 GB;   memoryInfo.free: 78.94 GB;   gpuTemperature: 25 C;   gpuEnergyUsage: 1856282859335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Initial GPU info before benchmarking model:\")\n",
    "get_gpu_info()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "print(f\"Benchmarking model ...\\n\")\n",
    "\n",
    "#torch.cuda.empty_cache()\n",
    "\n",
    "total_time, total_energy = benchmark_model(model, image, repeat)\n",
    "\n",
    "print_res(macs, total_time, total_energy)\n",
    "\n",
    "print(f\"GPU info after benchmarking model:\")\n",
    "get_gpu_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1565301.9154450016"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_energy / total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIT = 1024 * 1024 * 1024\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def get_gpu_info(handle):\n",
    "    memoryInfo = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "    gpuTemperature = pynvml.nvmlDeviceGetTemperature(handle, 0)\n",
    "    gpuEnergyUsage = pynvml.nvmlDeviceGetTotalEnergyConsumption(handle)\n",
    "    print(f\"memoryInfo.total: {memoryInfo.total/UNIT:.2f} GB;   memoryInfo.used: {memoryInfo.used/UNIT:.2f} GB;   memoryInfo.free: {memoryInfo.free/UNIT:.2f} GB;   gpuTemperature: {gpuTemperature} C;   gpuEnergyUsage: {gpuEnergyUsage}\\n\")\n",
    "\n",
    "\n",
    "def get_current_energy(handle):\n",
    "    gpuEnergyUsage = pynvml.nvmlDeviceGetTotalEnergyConsumption(handle)\n",
    "    return gpuEnergyUsage\n",
    "\n",
    "def print_res(macs, total_time, total_energy):\n",
    "    power_watts = total_energy / total_time\n",
    "    print(f\"Average Energy (per inference) => {total_energy:.4f} Joules\")\n",
    "    print(f\"Average Time (per inference) => {total_time*1000:.4f}ms\")\n",
    "    print(f\"Average Power (per inference) => {power_watts:.4f} Watts\")\n",
    "    print(f\"GOPS/W => {(repeat*macs/(1000**3)) / (total_energy*(10**-3)/total_time):.4f}\") # fixed to divide by (1000**3)\n",
    "    print(f\"GOPs => {((repeat*macs/(1000**3))/ total_time):.4f}\") # fixed to divide by (1000**3)\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "def benchmark_model(model, image, repeat, handle):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model = model.to(device)\n",
    "    input_tensor = image.to(device)\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    for _ in range(5): # warm up run\n",
    "        with torch.no_grad():\n",
    "          model(input_tensor)\n",
    "\n",
    "    total_time = 0\n",
    "    total_energy = 0\n",
    "\n",
    "    for _ in range(repeat):\n",
    "      energy_start = get_current_energy(handle)\n",
    "\n",
    "      torch.cuda.synchronize()\n",
    "      time_start = time.time()\n",
    "\n",
    "      with torch.no_grad():\n",
    "          output = model(input_tensor)\n",
    "\n",
    "      torch.cuda.synchronize()\n",
    "      time_end = time.time()\n",
    "\n",
    "      energy_end = get_current_energy(handle)\n",
    "\n",
    "      total_time += (time_end - time_start)\n",
    "      total_energy += (energy_end - energy_start)\n",
    "\n",
    "    return total_time / repeat, total_energy / repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU info before benchmarking model:\n",
      "memoryInfo.total: 80.00 GB;   memoryInfo.used: 1.06 GB;   memoryInfo.free: 78.94 GB;   gpuTemperature: 25 C;   gpuEnergyUsage: 1856353235037\n",
      "\n",
      "Benchmarking model ...\n",
      "\n",
      "Average Energy (per inference) => 275.4300 Joules\n",
      "Average Time (per inference) => 0.2030ms\n",
      "Average Power (per inference) => 1356979.2568 Watts\n",
      "GOPS/W => 0.0000\n",
      "GOPs => 277.5149\n",
      "\n",
      "GPU info after benchmarking model:\n",
      "memoryInfo.total: 80.00 GB;   memoryInfo.used: 1.06 GB;   memoryInfo.free: 78.94 GB;   gpuTemperature: 25 C;   gpuEnergyUsage: 1856353321896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pynvml.nvmlInit() # call init once\n",
    "handle = pynvml.nvmlDeviceGetHandleByIndex(0) # get the handle\n",
    "print(f\"Initial GPU info before benchmarking model:\")\n",
    "get_gpu_info(handle)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "image = image.to(device)\n",
    "print(f\"Benchmarking model ...\\n\")\n",
    "\n",
    "\n",
    "total_time, total_energy = benchmark_model(model, image, repeat, handle)\n",
    "\n",
    "print_res(macs, total_time, total_energy)\n",
    "\n",
    "print(f\"GPU info after benchmarking model:\")\n",
    "get_gpu_info(handle)\n",
    "pynvml.nvmlShutdown() # shutdown the device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "651",
   "language": "python",
   "name": "651"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
